Introduction to cloud native

Cloud native applications are highly distributed systems that
live in the cloud and are resilient to change.
. Systems are
made up of several services that communicate through a
network and are deployed in a dynamic environment where
everything keeps changing.


Cloud native technologies empower organizations to build and run scalable
applications in modern, dynamic environments such as public, private, and hybrid
clouds. Containers, service meshes, microservices, immutable infrastructure, and
declarative APIs exemplify this approach.
These techniques enable loosely coupled systems that are resilient, manageable, and
observable. Combined with robust automation, they allow engineers to make highimpact changes frequently and predictably with minimal toil

From this definition, I identify three points that I like to call
The Three Ps of Cloud Native:
Platforms—Cloud native applications run on
platforms based on dynamic, distributed
environments: the clouds (public, private, or
hybrid).
Properties—Cloud native applications are designed
to be scalable, loosely coupled, resilient,
manageable, and observable.
Practices—Practices around cloud native
applications—automation, continuous delivery, and
DevOps—include robust automation combined with
frequent and predictable change

The cloud is an IT infrastructure that supports the delivery of
computing resources to consumers according to the cloud
computing model.

Cloud computing is a model for enabling ubiquitous, convenient, on-demand network
access to a shared pool of configurable computing resources (e.g., networks, servers,
storage, applications, and services) that can be rapidly provisioned and released with
minimal management effort or service provider interaction.

The cloud provider manages the underlying cloud
infrastructure, so the consumer doesn’t need to worry about
physical resources like machines or networks. Companies
moving to the cloud can get all the computing resources
they need via a network (usually the internet) through a set
of APIs that allows them to provision and scale resources as
they need on an on-demand, self-service basis.


 Infrastructure as a Service (IaaS
 For
example, with the Infrastructure as a Service (IaaS) model,
the platform provides and manages computing, storage, and
networking resources, whereas the consumer provisions and
manages virtual machines. e AWS Elastic Compute Cloud
(EC2), Azure Virtual Machines, Google Compute Engine,
Alibaba Virtual Machines, and DigitalOcean Droplets

Container as a Service (CaaS)
Using the Container as a Service (CaaS) model, consumers
cannot control primitive virtualization resources. Instead,
they provision and manage containers. The cloud provider
takes care of provisioning the underlying resources that
fulfill the needs of those containers, such as by starting new
virtual machines and configuring networks to make them
accessible through the internet. Docker Swarm, Apache
Mesos, and Kubernetes are examples of tools used to build
container platforms. 

Platform as a Service (PaaS)

In the Platform as a Service (PaaS) model, the platform
provides infrastructure, tools, and APIs that developers can
use to build and deploy applications. For example, as a
developer, you can build a Java application, package it as a
Java Archive (JAR) file, and then deploy it to a platform
working according to the PaaS model. The platform provides
the Java runtime and other required middleware, and it can
also offer extra services like databases or messaging
systems.
. Examples of PaaS offerings are Cloud Foundry,
Heroku, AWS Elastic Beanstalk, Azure App Service, Google
App Engine, Alibaba Web App Service, and DigitalOcean App
Platform. In the past few years, vendors have been
converging on Kubernetes for building a new PaaS
experience for developers and operators. Examples of this
new generation of services are VMware Tanzu Application
Platform and RedHat OpenShift.


Function as a Service (FaaS)
The Function as a Service (FaaS) model relies on serverless
computing to let consumers focus on implementing the
business logic of their applications (often in the form of
functions), whereas the platform takes care of providing
servers and the rest of the infrastructure. Serverless
applications are triggered by events, such as HTTP requests
or messages. For example, you might code a function that
analyzes a data set whenever available from a message
queue and computes results according to some algorithms.
Examples of commercial FaaS offerings are Amazon AWS
Lambda, Microsoft Azure Functions, Google Cloud Functions,
and Alibaba Functions Compute. Examples of open source
FaaS offerings are Knative and Apache OpenWhisk


Software as a Service (SaaS):

The service with the highest abstraction is Software as a
Service (SaaS). In this model, consumers access
applications as users, while the cloud provider manages the
whole stack of software and infrastructure. Many companies
build their applications, use a CaaS or PaaS model to run
them, and then sell their usage to the end customers as
SaaS. The consumers of SaaS applications typically use thin
clients like web browsers or mobile devices to access them.
Examples of applications available as SaaS are Proton Mail,
GitHub, Plausible Analytics, and Microsoft Office 365.



Properties of cloud native
applications:
The CNCF identifies five main properties that cloud native
applications should have:scalability, loose coupling,
resilience, observability, and manageability.Cloud native is a
methodology for building and running applications that
exhibit those properties.
Cornelia Davis sums it up by stating
that “cloud-native software is defined by how you compute,
not about where you compute.”
5 In other words, the cloud is
about where, and cloud native is about how.

Scalability:
Cloud native applications are designed to scale, meaning
that they can support increasing workloads if provided with
additional resources.
Vertical scalability —Scaling vertically, or scaling
up or down, means adding hardware resources to
or removing them from the computing node, such
as CPU or memory.
Horizontal scalability —Scaling horizontally, or
scaling out or in, means adding more computing
nodes or containers to, or removing them from,
the system.

Loose coupling:
Loose coupling is an essential property of a system where
parts have as little knowledge of each other as possible. The
goal is to evolve each piece independently so that when one
is changed, the others don’t need to change accordingly.

Resilience:
A system is resilient if it provides its services even in the
presence of faults or environmental changes. Resilience is
“the capability of a hardware-software network to provide
and maintain an acceptable level of service in the face of
faults and challenges to normal operation.

Observability:

Observability is a property that comes from the world of
control theory. If you consider a system, observability is a
measure of how well you can infer its internal state from its
external outputs.


Manageability:, it’s the ability to modify
an application’s behavior without needing to change its code.
We want to make cloud native
applications configurable so we can modify their behavior
without changing their code and building a new release. It’s
common to make configurable settings like data source
URLs, service credentials, and certificates. For example,
depending on the environment, you may use different data
sources: one for development, one for testing, and one for
production. Other types of configuration could be feature
flags, which determine whether specific features should be
enabled at runtime.

Automation
The idea is to
automate repetitive manual tasks to accelerate the delivery
and deployment of cloud native applications. Many tasks can
be automated, from building applications to deploying them,
from provisioning infrastructure to managing configuration.
The most important advantage of automation is that it
makes processes and tasks repeatable and overall systems
more stable and reliable.In the cloud computing model, computing resources are
provisioned in an automated, self-service model, and they
can be increased or decreased elastically. Two significant
categories of automation for the cloud are infrastructure
provisioning and configuration management


Continuous delivery
Continuous delivery is “a software development discipline
where you build software in such a way that the software
can be released to production at any timeContinuous integration (CI) is a foundational practice in
continuous delivery. Developers commit their changes to the
mainline (the main branch) continuously (at least once a
day). At each commit, the software is automatically
compiled, tested, and packaged as executable artifacts (such
as JAR files or container images).
Continuous delivery (CD) builds on CI and focuses on
keeping the mainline always healthy and in a releasable
state. After an executable artifact is produced as part of the
integration with the mainline, the software is deployed to a
production-like environment. It goes through additional tests
to assess its releasability, such as user acceptance tests,
performance tests, security tests, compliance tests, and any
other tests that might increase the confidence that the
software can be released.

Containers
On the other hand, an OS container is a lightweight
executable package that includes everything needed to run
the application. Containers share the same kernel as the
host: there’s no need to bootstrap full operating systems to
add new isolated contexts.

 Orchestration
 Container orchestration helps you automate many different
tasks:
Managing clusters, bringing up and down machines
when necessary
Scheduling and deploying containers within a
cluster to a machine that meets the container
requirements for CPU and memory
Dynamically scaling containers for high availability
and resilience, leveraging health monitoring
Setting up networks for containers to communicate
with each other, defining routing, service
discovery, and load balancing
Exposing services to the internet, establishing
ports and networks
Allocating resources to containers according to
specific criteria
Configuring the applications running within the
containers
Ensuring security and enforcing access control
policies

.6.3 Serverless
After moving from virtual machines to containers, we can
abstract the infrastructure even more: that’s where
serverless technologies are placed. The serverless computing
model enables developers to focus on implementing the
business logic for their applications.

The name serverless might be misleading. Of course there is
a server. The difference is that you do not need to manage it
or orchestrate the application’s deployment on it. That’s a
platform responsibility now. When you use an orchestrator
like Kubernetes, you must still consider infrastructure
provisioning, capacity planning, and scaling. In contrast, a
serverless platform takes care of setting up the underlying
infrastructure needed by the applications, including virtual
machines, containers, and dynamic scaling.


Architectures for cloud native
applications


Summary
Cloud native applications are highly distributed
systems that are specifically designed for and live
in the cloud.
The cloud is an IT infrastructure provided as a
commodity in terms of computing, storage, and
networking resources.
In the cloud, users pay only for the actual
resources they use.
Cloud platforms deliver their services at different
levels of abstraction: infrastructure (IaaS),
container (CaaS), platform (PaaS), functions
(FaaS), or software (SaaS).
Cloud native applications are horizontally scalable,
loosely coupled, highly cohesive, resilient to faults,
manageable, and observable.
Cloud native development is supported by
automation, continuous delivery, and DevOps.
Continuous delivery is a holistic engineering
practice for delivering high-quality software
quickly, reliably, and safely.
DevOps is a culture enabling collaboration among
different roles to deliver business value together.
Modern businesses go cloud native to produce
software that can be delivered quickly, can be
scaled dynamically depending on demand, and is
always available and resilient to failures while
optimizing costs.
Containers (such as Docker containers) can be
used as computational units when designing cloud
native systems. They are more lightweight than
virtual machines and provide portability,
immutability, and flexibility.
Dedicated platforms (such as Kubernetes) offer
services to manage containers without directly
handling the underlying layers. They provide
container orchestration, cluster management,
network services, and scheduling.
Serverless computing is a model where the
platform (such as Knative) manages servers and
the underlying infrastructure, and the developer
only focuses on the business logic. The backend
functionality is enabled on a pay-per-use basis for
cost optimization.
A microservices architecture can be used to build
cloud native applications, but it’s not a
requirement.
To design cloud native applications, we’ll use a
service-based style characterized by services and
their interactions.
Cloud native services can be classified into
application services (stateless) and data services
(stateful).

--------------------------------------------------------
 Cloud native development
principles: 12 Factors and
beyond
One codebase, one application


These 15 factors will guide you throughout the book since
they are a good starting point for developing cloud native
applications

2.1.1 One codebase, one application
2.1.2 API first
 Dependency management
 All application dependencies should be declared explicitly in
a manifest and be available for the dependency manager to
download from a central repository

 Design, build, release, run
 
 
 .1.5 Configuration, credentials, and code
 The 15-Factor methodology defines configuration as
everything likely to change between deployments. Whenever
you need to change the configuration for an application, you
should be able to do so without any changes in the code,
and without building the application again.

The configuration might include resource handles to backing
services like a database or a messaging system, credentials
to access third-party APIs, and feature flags. Ask yourself if
any credential or environment-specific information would be
compromised should your codebase suddenly become public.
That will tell you whether you have correctly externalized the


configuration.


2.1.6 Logs



5 Persisting and managing data in the
cloud
This chapter covers
Understanding databases in a cloud native system
Implementing data persistence with Spring Data JDBC
Testing data persistence with Spring Boot and Testcontainers
Managing databases in production with Flyway

6 Containerizing Spring Boot
This chapter covers
Working with container images on Docker
Packaging Spring Boot applications as container images
Managing Spring Boot containers with Docker Compose
Automating image build and push with GitHub Actions.


7 Kubernetes fundamentals for Spring
Boot
This chapter covers
Moving from Docker to Kubernetes
Deploying Spring Boot applications on Kubernetes
Understanding service discovery and load balancing
Building scalable and disposable applications
Establishing a local Kubernetes development workflow
Validating Kubernetes manifests with GitHub Actions


8 Reactive Spring: Resilience and
scalability
This chapter covers
Understanding reactive programming with Reactor and Spring
Building reactive servers with Spring WebFlux and Spring Data
R2DBC
Building reactive clients with WebClient
Improving resilience for applications with Reactor
Testing reactive applications with Spring and Testcontainers


9 API gateway and circuit breakers
This chapter covers
Implementing edge services with Spring Cloud Gateway and
Reactive Spring
Configuring circuit breakers with Spring Cloud Circuit Breaker
and Resilience4J
Defining rate limiters with Spring Cloud Gateway and Redis
Managing distributed sessions with Spring Session Data Redis
Routing application traffic with Kubernetes Ingress


Event-driven applications and
functions
This chapter covers
Understanding event-driven architectures
Using RabbitMQ as a message broker
Implementing functions with Spring Cloud Function
Processing events with Spring Cloud Stream
Producing and consuming events with Spring Cloud Stream


1 Security: Authentication and SPA
This chapter covers
Understanding the Spring Security fundamentals
Managing user accounts with Keycloak
Working with OpenID Connect, JWT, and Keycloak
Authenticating users with Spring Security and OpenID Connect
Testing Spring Security and OpenID Connect


12 Security: Authorization and
auditing
This chapter covers
Authorization and roles with Spring Cloud Gateway and OAuth2
Protecting APIs with Spring Security and OAuth2 (imperative)
Protecting APIs with Spring Security and OAuth2 (reactive)
Protecting and auditing data with Spring Security and Spring
Data


13 Observability and monitoring
This chapter covers
Logging with Spring Boot, Loki, and Fluent Bit
Using health probes with Spring Boot Actuator and Kubernetes
Producing metrics with Spring Boot Actuator, Prometheus, and
Grafana
Configuring distributed tracing with OpenTelemetry and Tempo
Managing applications with Spring Boot Actuator


14 Configuration and secrets
management
This chapter covers
Configuring applications on Kubernetes
Using ConfigMaps and Secrets in Kubernetes
Managing deployments and configuration with Kustomize



15 Continuous delivery and GitOps
This chapter covers
Understanding continuous delivery and release management
Configuring Spring Boot for production with Kustomize
Deploying in production with GitOps and Kubernetes


This chapter covers
Producing native images with Spring Native and GraalVM
Building serverless applications with Spring Cloud Function
Deploying serverless applications with Knative and Kubernetes


 GraalVM also provides runtimes to
execute code written in other languages like JavaScript,
Python, and R. You can even write polyglot applications,
including Python scripts in your Java code, for example.
GraalVM offers two primary operational modes. 

What makes
GraalVM so innovative and popular in the serverless context
is the Native Image mode. Rather than compiling your Java
code into bytecode and relying on a JVM to interpret it and
convert it to machine code, GraalVM offers a new technology
(the Native Image builder) that compiles Java applications
directly into machine code, obtaining a native executable or
native image that contains the whole machine code
necessary for its execution.
Java applications compiled as native images have faster
startup times, optimized memory consumption, and instant
peak performance compared to the JVM options. G

